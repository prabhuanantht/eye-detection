{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Eye Detection \"Super Model\" Training Pipeline\n",
                "\n",
                "This notebook trains a YOLOv8 model to detect eyes. It uses aggressive data augmentation (Mosaic, Mixup, Random Crop/Scale) to ensure the model is robust to:\n",
                "- Partial faces (half-face, zoomed in)\n",
                "- Crowds (small faces)\n",
                "- Occlusions\n",
                "\n",
                "**Instructions:**\n",
                "1. Run all cells in order.\n",
                "2. The dataset will be downloaded and prepared automatically.\n",
                "3. Training will run for 50 epochs.\n",
                "4. The final model (`best.pt`) will be zipped and downloaded to your computer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Setup Environment\n",
                "!pip install ultralytics opencv-python-headless\n",
                "\n",
                "import os\n",
                "import shutil\n",
                "import cv2\n",
                "import numpy as np\n",
                "import glob\n",
                "import requests\n",
                "import zipfile\n",
                "from ultralytics import YOLO\n",
                "from google.colab import files"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Download Helen Dataset\n",
                "DATASET_URL = \"http://www.ifp.illinois.edu/~vuongle2/helen/data/helen_1.zip\" # Example URL, usually needs Kaggle API or direct link. \n",
                "# Since direct links are unstable, we will assume the user might need to upload it OR we use a stable mirror if available.\n",
                "# For this script, we'll try to download from a source, but if it fails, you can upload 'helen_dataset.zip' manually.\n",
                "\n",
                "# NOTE: The official Helen link is often down. \n",
                "# We will simulate the structure or use a placeholder if you don't have the zip.\n",
                "# Ideally, upload 'helen_dataset.zip' to the Colab files area before running this if the download fails.\n",
                "\n",
                "def download_file(url, filename):\n",
                "    response = requests.get(url, stream=True)\n",
                "    if response.status_code == 200:\n",
                "        with open(filename, 'wb') as f:\n",
                "            for chunk in response.iter_content(1024):\n",
                "                f.write(chunk)\n",
                "        print(f\"Downloaded {filename}\")\n",
                "    else:\n",
                "        print(f\"Failed to download. Status: {response.status_code}\")\n",
                "\n",
                "# If you have the zip, uncomment this line and skip download:\n",
                "# !unzip -q helen_dataset.zip -d helen_dataset\n",
                "\n",
                "# Placeholder for Kaggle download command if you have API key:\n",
                "# !kaggle datasets download -d helen-dataset-url\n",
                "\n",
                "print(\"Please upload 'helen_dataset.zip' to the Files section if not already present.\")\n",
                "print(\"Assuming 'helen_dataset.zip' is present in the current directory...\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Extract Dataset\n",
                "if os.path.exists('helen_dataset.zip'):\n",
                "    !unzip -q -o helen_dataset.zip -d helen_dataset\n",
                "    print(\"Extracted helen_dataset.zip\")\n",
                "else:\n",
                "    print(\"Error: helen_dataset.zip not found! Please upload it.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Data Preparation (Landmarks -> YOLO)\n",
                "# This script converts the Helen .pts landmarks to YOLO bounding boxes\n",
                "\n",
                "DATASET_DIR = \"helen_dataset\"\n",
                "OUTPUT_DIR = \"data\"\n",
                "IMAGES_DIR = os.path.join(OUTPUT_DIR, \"images\")\n",
                "LABELS_DIR = os.path.join(OUTPUT_DIR, \"labels\")\n",
                "\n",
                "# Clean output directory\n",
                "if os.path.exists(OUTPUT_DIR):\n",
                "    shutil.rmtree(OUTPUT_DIR)\n",
                "\n",
                "# Create directories\n",
                "for split in ['train', 'val']:\n",
                "    os.makedirs(os.path.join(IMAGES_DIR, split), exist_ok=True)\n",
                "    os.makedirs(os.path.join(LABELS_DIR, split), exist_ok=True)\n",
                "\n",
                "def convert_to_yolo(img_width, img_height, x_min, y_min, x_max, y_max):\n",
                "    x_center = (x_min + x_max) / 2.0 / img_width\n",
                "    y_center = (y_min + y_max) / 2.0 / img_height\n",
                "    width = (x_max - x_min) / img_width\n",
                "    height = (y_max - y_min) / img_height\n",
                "    return 0, x_center, y_center, width, height\n",
                "\n",
                "def process_data():\n",
                "    image_files = glob.glob(f\"{DATASET_DIR}/**/*.jpg\", recursive=True)\n",
                "    print(f\"Found {len(image_files)} images.\")\n",
                "    \n",
                "    processed_count = 0\n",
                "    for i, img_path in enumerate(image_files):\n",
                "        # Find corresponding .pts or .txt file\n",
                "        pts_path = os.path.splitext(img_path)[0] + \".pts\"\n",
                "        if not os.path.exists(pts_path):\n",
                "            pts_path = os.path.splitext(img_path)[0] + \".txt\"\n",
                "            if not os.path.exists(pts_path):\n",
                "                continue\n",
                "            \n",
                "        img = cv2.imread(img_path)\n",
                "        if img is None:\n",
                "            continue\n",
                "        h, w = img.shape[:2]\n",
                "        \n",
                "        landmarks = []\n",
                "        try:\n",
                "            with open(pts_path, 'r') as f:\n",
                "                lines = f.readlines()\n",
                "            \n",
                "            start_parsing = False\n",
                "            for line in lines:\n",
                "                line = line.strip()\n",
                "                if line == '{' or (line.replace('.','',1).isdigit() and len(line.split())==2 and 'version' not in line):\n",
                "                     # Handle both .pts header and raw coordinate lines\n",
                "                    start_parsing = True\n",
                "                    if line == '{': continue\n",
                "                \n",
                "                if line == '}':\n",
                "                    break\n",
                "                \n",
                "                if start_parsing or (len(line.split())==2 and line[0].isdigit()):\n",
                "                    parts = line.split()\n",
                "                    if len(parts) >= 2:\n",
                "                        try:\n",
                "                            x, y = float(parts[0]), float(parts[1])\n",
                "                            landmarks.append((x, y))\n",
                "                        except ValueError:\n",
                "                            pass\n",
                "        except Exception as e:\n",
                "            print(f\"Error parsing {pts_path}: {e}\")\n",
                "            continue\n",
                "                    \n",
                "        if len(landmarks) != 68:\n",
                "             # Try to take last 68 if more\n",
                "            if len(landmarks) > 68:\n",
                "                landmarks = landmarks[-68:]\n",
                "            else:\n",
                "                continue\n",
                "\n",
                "        # Extract eye regions (Left: 36-41, Right: 42-47)\n",
                "        left_eye_pts = landmarks[36:42]\n",
                "        right_eye_pts = landmarks[42:48]\n",
                "        \n",
                "        yolo_labels = []\n",
                "        \n",
                "        for pts in [left_eye_pts, right_eye_pts]:\n",
                "            pts_np = np.array(pts)\n",
                "            x_min = np.min(pts_np[:, 0])\n",
                "            y_min = np.min(pts_np[:, 1])\n",
                "            x_max = np.max(pts_np[:, 0])\n",
                "            y_max = np.max(pts_np[:, 1])\n",
                "            \n",
                "            # Add padding (30%)\n",
                "            pad_x = (x_max - x_min) * 0.3\n",
                "            pad_y = (y_max - y_min) * 0.3\n",
                "            \n",
                "            x_min = max(0, x_min - pad_x)\n",
                "            y_min = max(0, y_min - pad_y)\n",
                "            x_max = min(w, x_max + pad_x)\n",
                "            y_max = min(h, y_max + pad_y)\n",
                "            \n",
                "            cls, xc, yc, bw, bh = convert_to_yolo(w, h, x_min, y_min, x_max, y_max)\n",
                "            yolo_labels.append(f\"{cls} {xc} {yc} {bw} {bh}\")\n",
                "            \n",
                "        # Split train/val\n",
                "        split = 'train' if i < len(image_files) * 0.8 else 'val'\n",
                "        \n",
                "        shutil.copy(img_path, os.path.join(IMAGES_DIR, split, os.path.basename(img_path)))\n",
                "        \n",
                "        label_filename = os.path.splitext(os.path.basename(img_path))[0] + \".txt\"\n",
                "        with open(os.path.join(LABELS_DIR, split, label_filename), 'w') as f:\n",
                "            f.write('\\n'.join(yolo_labels))\n",
                "        \n",
                "        processed_count += 1\n",
                "            \n",
                "    print(f\"Data preparation complete. Processed {processed_count} images.\")\n",
                "\n",
                "process_data()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. Configure Dataset YAML\n",
                "yaml_content = \"\"\"\n",
                "names:\n",
                "  0: eye\n",
                "path: /content/data\n",
                "train: images/train\n",
                "val: images/val\n",
                "\"\"\"\n",
                "with open('dataset.yaml', 'w') as f:\n",
                "    f.write(yaml_content)\n",
                "print(\"Created dataset.yaml\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. Train \"Super Model\"\n",
                "# We use aggressive augmentation to force the model to learn robust features\n",
                "\n",
                "model = YOLO('yolov8n.pt') # Start with Nano model for speed, use 'yolov8s.pt' for more accuracy\n",
                "\n",
                "results = model.train(\n",
                "    data='dataset.yaml',\n",
                "    epochs=50,           # Sufficient time to converge\n",
                "    imgsz=640,\n",
                "    batch=16,\n",
                "    patience=10,         # Early stopping\n",
                "    \n",
                "    # --- Super Model Augmentations ---\n",
                "    mosaic=1.0,          # 100% chance to stitch 4 images (Simulates crowds)\n",
                "    mixup=0.1,           # Blend images (General robustness)\n",
                "    degrees=15.0,        # Rotation +/- 15 deg\n",
                "    scale=0.5,           # Scale image +/- 50% (Simulates partial/zoomed faces)\n",
                "    erasing=0.4,         # Randomly erase patches (Simulates occlusion)\n",
                "    \n",
                "    project='runs/detect',\n",
                "    name='eye_super_model',\n",
                "    exist_ok=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 7. Export and Download\n",
                "!zip -r eye_super_model.zip runs/detect/eye_super_model/weights/best.pt\n",
                "files.download('eye_super_model.zip')\n",
                "print(\"Download started! Place this file in your app's ml_pipeline/runs/detect/ folder.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}